{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0ca269a",
      "metadata": {
        "id": "e0ca269a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "753a9a31",
      "metadata": {
        "id": "753a9a31"
      },
      "outputs": [],
      "source": [
        "class DenseLayer(nn.Sequential):\n",
        "    def __init__(self, in_channels, growth_rate):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(in_channels))\n",
        "        self.add_module('relu', nn.ReLU(True))\n",
        "        self.add_module('conv', nn.Conv2d(in_channels, growth_rate, kernel_size=3,\n",
        "                                          stride=1, padding=1, bias=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return super(DenseLayer, self).forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "82d221b4",
      "metadata": {
        "id": "82d221b4"
      },
      "outputs": [],
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, n_layers, upsample=False):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.upsample = upsample\n",
        "        self.layers = nn.ModuleList([DenseLayer(\n",
        "            in_channels + i * growth_rate, growth_rate)\n",
        "            for i in range(n_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.upsample:\n",
        "            new_features = []\n",
        "            # we pass all previous activations into each dense layer normally\n",
        "            # But we only store each dense layer's output in the new_features array\n",
        "            for layer in self.layers:\n",
        "                out = layer(x)\n",
        "                x = torch.cat([x, out], 1)\n",
        "                new_features.append(out)\n",
        "            return torch.cat(new_features, 1)\n",
        "        else:\n",
        "            for layer in self.layers:\n",
        "                out = layer(x)\n",
        "                x = torch.cat([x, out], 1)  # 1 = channel axis\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c6c8a9c0",
      "metadata": {
        "id": "c6c8a9c0"
      },
      "outputs": [],
      "source": [
        "class TransitionDown(nn.Sequential):\n",
        "    def __init__(self, in_channels):\n",
        "        super(TransitionDown, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_features=in_channels))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(in_channels, in_channels,\n",
        "                                          kernel_size=1, stride=1,\n",
        "                                          padding=0, bias=True))\n",
        "        self.add_module('maxpool', nn.MaxPool2d(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return super(TransitionDown, self).forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "177ece9c",
      "metadata": {
        "id": "177ece9c"
      },
      "outputs": [],
      "source": [
        "class TransitionUp(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(TransitionUp, self).__init__()\n",
        "        self.convTrans = nn.Sequential(nn.Upsample(mode='nearest', scale_factor=2),\n",
        "                                       nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        out = self.convTrans(x)\n",
        "        out = center_crop_(out, skip.size(2), skip.size(3))\n",
        "        out = torch.cat([out, skip], 1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7a5d7e12",
      "metadata": {
        "id": "7a5d7e12"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Sequential):\n",
        "    def __init__(self, in_channels, growth_rate, n_layers):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.add_module('bottleneck', DenseBlock(\n",
        "            in_channels, growth_rate, n_layers, upsample=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return super(Bottleneck, self).forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "596e66ad",
      "metadata": {
        "id": "596e66ad"
      },
      "outputs": [],
      "source": [
        "def center_crop_(layer, max_height, max_width):\n",
        "    _, _, h, w = layer.size()\n",
        "    xy1 = (w - max_width) // 2\n",
        "    xy2 = (h - max_height) // 2\n",
        "    return layer[:, :, xy2:(xy2 + max_height), xy1:(xy1 + max_width)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2c5261f1",
      "metadata": {
        "id": "2c5261f1"
      },
      "outputs": [],
      "source": [
        "class FCDenseNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, down_blocks=(5, 5, 5, 5, 5),\n",
        "                 up_blocks=(5, 5, 5, 5, 5), bottleneck_layers=5,\n",
        "                 growth_rate=16, out_chans_first_conv=48, n_classes=1):\n",
        "        super(FCDenseNet, self).__init__()\n",
        "        self.down_blocks = down_blocks\n",
        "        self.up_blocks = up_blocks\n",
        "        cur_channels_count = 0\n",
        "        skip_connection_channel_counts = []\n",
        "\n",
        "        # First Convolution\n",
        "        self.add_module('firstconv', nn.Conv2d(in_channels=in_channels,\n",
        "                                               out_channels=out_chans_first_conv, kernel_size=3,\n",
        "                                               stride=1, padding=1, bias=True))\n",
        "        cur_channels_count = out_chans_first_conv\n",
        "        self.denseBlocksDown = nn.ModuleList([])\n",
        "        self.transDownBlocks = nn.ModuleList([])\n",
        "        for i in range(len(down_blocks)):\n",
        "            self.denseBlocksDown.append(\n",
        "                DenseBlock(cur_channels_count, growth_rate, down_blocks[i]))\n",
        "            cur_channels_count += (growth_rate * down_blocks[i])\n",
        "            skip_connection_channel_counts.insert(0, cur_channels_count)\n",
        "            self.transDownBlocks.append(TransitionDown(cur_channels_count))\n",
        "\n",
        "        self.add_module('bottleneck', Bottleneck(cur_channels_count,\n",
        "                                                 growth_rate, bottleneck_layers))\n",
        "        prev_block_channels = growth_rate * bottleneck_layers\n",
        "        cur_channels_count += prev_block_channels\n",
        "        self.transUpBlocks = nn.ModuleList([])\n",
        "        self.denseBlocksUp = nn.ModuleList([])\n",
        "        for i in range(len(up_blocks) - 1):\n",
        "            self.transUpBlocks.append(TransitionUp(prev_block_channels, prev_block_channels))\n",
        "            cur_channels_count = prev_block_channels + skip_connection_channel_counts[i]\n",
        "\n",
        "            self.denseBlocksUp.append(DenseBlock(\n",
        "                cur_channels_count, growth_rate, up_blocks[i],\n",
        "                upsample=True))\n",
        "            prev_block_channels = growth_rate * up_blocks[i]\n",
        "            cur_channels_count += prev_block_channels\n",
        "        self.transUpBlocks.append(TransitionUp(\n",
        "            prev_block_channels, prev_block_channels))\n",
        "        cur_channels_count = prev_block_channels + skip_connection_channel_counts[-1]\n",
        "\n",
        "        self.denseBlocksUp.append(DenseBlock(\n",
        "            cur_channels_count, growth_rate, up_blocks[-1],\n",
        "            upsample=False))\n",
        "        cur_channels_count += growth_rate * up_blocks[-1]\n",
        "\n",
        "        self.finalConv = nn.Conv2d(in_channels=cur_channels_count,\n",
        "                                   out_channels=n_classes, kernel_size=1, stride=1,\n",
        "                                   padding=0, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.firstconv(x)\n",
        "\n",
        "        skip_connections = []\n",
        "        for i in range(len(self.down_blocks)):\n",
        "            out = self.denseBlocksDown[i](out)\n",
        "            skip_connections.append(out)\n",
        "            out = self.transDownBlocks[i](out)\n",
        "\n",
        "        out = self.bottleneck(out)\n",
        "        for i in range(len(self.up_blocks)):\n",
        "            skip = skip_connections.pop()\n",
        "            out = self.transUpBlocks[i](out, skip)\n",
        "            out = self.denseBlocksUp[i](out)\n",
        "\n",
        "        out = torch.abs(self.finalConv(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4fc1ea60",
      "metadata": {
        "id": "4fc1ea60"
      },
      "outputs": [],
      "source": [
        "def FCDenseNet57(n_classes):\n",
        "    return FCDenseNet(\n",
        "        in_channels=3, down_blocks=(4, 4, 4, 4, 4),\n",
        "        up_blocks=(4, 4, 4, 4, 4), bottleneck_layers=4,\n",
        "        growth_rate=12, out_chans_first_conv=48, n_classes=n_classes)\n",
        "\n",
        "\n",
        "def FCDenseNet67(n_classes):\n",
        "    return FCDenseNet(\n",
        "        in_channels=3, down_blocks=(5, 5, 5, 5, 5),\n",
        "        up_blocks=(5, 5, 5, 5, 5), bottleneck_layers=5,\n",
        "        growth_rate=16, out_chans_first_conv=48, n_classes=n_classes)\n",
        "\n",
        "\n",
        "def FCDenseNet103(n_classes):\n",
        "    return FCDenseNet(\n",
        "        in_channels=3, down_blocks=(4, 5, 7, 10, 12),\n",
        "        up_blocks=(12, 10, 7, 5, 4), bottleneck_layers=15,\n",
        "        growth_rate=16, out_chans_first_conv=48, n_classes=n_classes)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, depth=6, wf=6, padding=True,\n",
        "                 up_mode='upconv'):\n",
        "        super(UNet, self).__init__()\n",
        "        assert up_mode in ('upconv', 'upsample')\n",
        "        self.padding = padding\n",
        "        self.depth = depth\n",
        "        prev_channels = in_channels\n",
        "        self.down_path = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            self.down_path.append(UNetConvBlock(prev_channels, 2 ** (wf + i),\n",
        "                                                padding))\n",
        "            prev_channels = 2 ** (wf + i)\n",
        "\n",
        "        self.up_path = nn.ModuleList()\n",
        "        for i in reversed(range(depth - 1)):\n",
        "            self.up_path.append(UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode,\n",
        "                                            padding))\n",
        "            prev_channels = 2 ** (wf + i)\n",
        "        self.last = nn.Conv2d(prev_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        blocks = []\n",
        "        for i, down in enumerate(self.down_path):\n",
        "            x = down(x)\n",
        "            if i != len(self.down_path) - 1:\n",
        "                blocks.append(x)\n",
        "                x = F.avg_pool2d(x, 2)\n",
        "                # x = F.max_pool2d(x, 2)\n",
        "        for i, up in enumerate(self.up_path):\n",
        "            x = up(x, blocks[-i - 1])\n",
        "\n",
        "        return self.last(x)\n",
        "\n",
        "\n",
        "class UNetConvBlock(nn.Module):\n",
        "    def __init__(self, in_size, out_size, padding):\n",
        "        super(UNetConvBlock, self).__init__()\n",
        "        block = []\n",
        "\n",
        "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3,\n",
        "                               padding=int(padding)))\n",
        "        block.append(nn.ReLU())\n",
        "\n",
        "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3,\n",
        "                               padding=int(padding)))\n",
        "        block.append(nn.ReLU())\n",
        "\n",
        "        self.block = nn.Sequential(*block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UNetUpBlock(nn.Module):\n",
        "    def __init__(self, in_size, out_size, up_mode, padding):\n",
        "        super(UNetUpBlock, self).__init__()\n",
        "        if up_mode == 'upconv':\n",
        "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=3, stride=2, padding=int(padding),\n",
        "                                         output_padding=int(padding))\n",
        "            # self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2,\n",
        "            #                              stride=2)\n",
        "        elif up_mode == 'upsample':\n",
        "            self.up = nn.Sequential(nn.Upsample(mode='nearest', scale_factor=2),\n",
        "                                    nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
        "\n",
        "        self.conv_block = UNetConvBlock(in_size, out_size, padding)\n",
        "\n",
        "    def forward(self, x, bridge):\n",
        "        up = self.up(x)\n",
        "        crop1 = center_crop(bridge, up.shape[2:])\n",
        "        out = torch.cat([up, crop1], 1)\n",
        "        out = self.conv_block(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def center_crop(layer, target_size):\n",
        "    _, _, layer_height, layer_width = layer.size()\n",
        "    diff_y = (layer_height - target_size[0]) // 2\n",
        "    diff_x = (layer_width - target_size[1]) // 2\n",
        "    return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n",
        "\n",
        "\n",
        "def images_warping(images, source_coord_w_flat, source_coord_h_flat, padding_mode=\"zeros\"):\n",
        "    batch_num, channels, image_h, image_w = images.shape\n",
        "    warped_images_flat = _bilinear_interpolate(images.permute(0, 2, 3, 1), x=source_coord_w_flat,\n",
        "                                               y=source_coord_h_flat, padding_mode=padding_mode)\n",
        "    warped_images = warped_images_flat.reshape(batch_num, image_h, image_w, channels).permute(0, 3, 1, 2)\n",
        "    return warped_images\n",
        "\n",
        "\n",
        "def _bilinear_interpolate(im, x, y, padding_mode=\"zeros\"):\n",
        "    num_batch, height, width, channels = im.shape\n",
        "    # Range [-1, 1]\n",
        "    grid = torch.cat([torch.tensor(2.0).float().cuda() *\n",
        "                      (x.reshape(num_batch, height, width, 1) / torch.tensor(width).float().cuda())\n",
        "                      - torch.tensor(1.0).float().cuda(), torch.tensor(2.0).float().cuda() * (\n",
        "                              y.reshape(num_batch, height, width, 1) / torch.tensor(\n",
        "                          height).float().cuda()) - torch.tensor(\n",
        "        1.0).float().cuda()], dim=-1)\n",
        "\n",
        "    return torch.nn.functional.grid_sample(input=im.permute(0, 3, 1, 2), grid=grid, mode='bilinear',\n",
        "                                           padding_mode=padding_mode).permute(0, 2, 3, 1)\n",
        "\n",
        "\n",
        "class DepthScalingLayer(nn.Module):\n",
        "    def __init__(self, epsilon=1.0e-8):\n",
        "        super(DepthScalingLayer, self).__init__()\n",
        "        self.epsilon = torch.tensor(epsilon).float().cuda()\n",
        "        self.zero = torch.tensor(0.0).float().cuda()\n",
        "        self.one = torch.tensor(1.0).float().cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        absolute_depth_estimations, input_sparse_depths, input_weighted_sparse_masks = x\n",
        "        input_sparse_binary_masks = torch.where(input_weighted_sparse_masks > 1.0e-8, self.one, self.zero)\n",
        "        mean_sparse_depths = torch.sum(input_sparse_depths * input_sparse_binary_masks, dim=(1, 2, 3),\n",
        "                                       keepdim=True) / torch.sum(input_sparse_binary_masks, dim=(1, 2, 3), keepdim=True)\n",
        "        above_mean_masks = torch.where(input_sparse_depths > 0.5 * mean_sparse_depths, self.one, self.zero)\n",
        "        sparse_scale_maps = input_sparse_depths * above_mean_masks / (self.epsilon + absolute_depth_estimations)\n",
        "        mean_scales = torch.sum(sparse_scale_maps, dim=(1, 2, 3), keepdim=True) / torch.sum(above_mean_masks,\n",
        "                                                                                            dim=(1, 2, 3), keepdim=True)\n",
        "        centered_sparse_scale_maps = sparse_scale_maps - above_mean_masks * mean_scales\n",
        "        scale_stds = torch.sqrt(torch.sum(centered_sparse_scale_maps * centered_sparse_scale_maps, dim=(1, 2, 3),\n",
        "                                          keepdim=False) / torch.sum(above_mean_masks, dim=(1, 2, 3), keepdim=False))\n",
        "        scales = torch.sum(sparse_scale_maps, dim=(1, 2, 3)) / torch.sum(above_mean_masks, dim=(1, 2, 3))\n",
        "        return torch.mul(scales.reshape(-1, 1, 1, 1), absolute_depth_estimations), torch.mean(scale_stds / mean_scales)\n",
        "\n",
        "\n",
        "class FlowfromDepthLayer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FlowfromDepthLayer, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        depth_maps_1, img_masks, translation_vectors, rotation_matrices, intrinsic_matrices = x\n",
        "        flow_image = _flow_from_depth(depth_maps_1, img_masks, translation_vectors, rotation_matrices,\n",
        "                                      intrinsic_matrices)\n",
        "        return flow_image\n",
        "\n",
        "\n",
        "def _warp_coordinate_generate(depth_maps_1, img_masks, translation_vectors, rotation_matrices, intrinsic_matrices):\n",
        "    # Generate a meshgrid for each depth map to calculate value\n",
        "    num_batch, height, width, channels = depth_maps_1.shape\n",
        "\n",
        "    y_grid, x_grid = torch.meshgrid(\n",
        "        [torch.arange(start=0, end=height, dtype=torch.float32).cuda(),\n",
        "         torch.arange(start=0, end=width, dtype=torch.float32).cuda()])\n",
        "\n",
        "    x_grid = x_grid.reshape(1, height, width, 1)\n",
        "    y_grid = y_grid.reshape(1, height, width, 1)\n",
        "\n",
        "    ones_grid = torch.ones((1, height, width, 1), dtype=torch.float32).cuda()\n",
        "    eye = torch.eye(3).float().cuda().reshape(1, 3, 3).expand(intrinsic_matrices.shape[0], -1, -1)\n",
        "    intrinsic_matrices_inverse, _ = torch.solve(eye, intrinsic_matrices)\n",
        "\n",
        "    rotation_matrices_inverse = rotation_matrices.transpose(1, 2)\n",
        "    temp_mat = torch.bmm(intrinsic_matrices, rotation_matrices_inverse)\n",
        "    W = torch.bmm(temp_mat, -translation_vectors)\n",
        "    M = torch.bmm(temp_mat, intrinsic_matrices_inverse)\n",
        "\n",
        "    mesh_grid = torch.cat((x_grid, y_grid, ones_grid), dim=-1).reshape(height, width, 3, 1)\n",
        "    intermediate_result = torch.matmul(M.reshape(-1, 1, 1, 3, 3), mesh_grid).reshape(-1, height, width, 3)\n",
        "\n",
        "    depth_maps_2_calculate = W.reshape(-1, 3).narrow(dim=-1, start=2, length=1).reshape(-1, 1, 1, 1) + torch.mul(\n",
        "        depth_maps_1,\n",
        "        intermediate_result.narrow(dim=-1, start=2, length=1).reshape(-1, height,\n",
        "                                                                      width, 1))\n",
        "    depth_maps_2_calculate = torch.tensor(1.0e30).float().cuda() * (torch.tensor(1.0).float().cuda() - img_masks) + \\\n",
        "                             img_masks * depth_maps_2_calculate\n",
        "    u_2 = (W.reshape(-1, 3).narrow(dim=-1, start=0, length=1).reshape(-1, 1, 1, 1) + torch.mul(depth_maps_1,\n",
        "                                                                                               intermediate_result.narrow(\n",
        "                                                                                                   dim=-1, start=0,\n",
        "                                                                                                   length=1).reshape(-1,\n",
        "                                                                                                                     height,\n",
        "                                                                                                                     width,\n",
        "                                                                                                                     1))) / depth_maps_2_calculate\n",
        "\n",
        "    v_2 = (W.reshape(-1, 3).narrow(dim=-1, start=1, length=1).reshape(-1, 1, 1, 1) + torch.mul(depth_maps_1,\n",
        "                                                                                               intermediate_result.narrow(\n",
        "                                                                                                   dim=-1, start=1,\n",
        "                                                                                                   length=1).reshape(-1,\n",
        "                                                                                                                     height,\n",
        "                                                                                                                     width,\n",
        "                                                                                                                     1))) / depth_maps_2_calculate\n",
        "    return [u_2, v_2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "993b75bb",
      "metadata": {
        "id": "993b75bb"
      },
      "outputs": [],
      "source": [
        "def _flow_from_depth(depth_maps_1, img_masks, translation_vectors, rotation_matrices, intrinsic_matrices):\n",
        "    depth_maps_1 = depth_maps_1.permute(0, 2, 3, 1)\n",
        "    img_masks = img_masks.permute(0, 2, 3, 1)\n",
        "    num_batch, height, width, channels = depth_maps_1.shape\n",
        "\n",
        "    y_grid, x_grid = torch.meshgrid(\n",
        "        [torch.arange(start=0, end=height, dtype=torch.float32).cuda(),\n",
        "         torch.arange(start=0, end=width, dtype=torch.float32).cuda()])\n",
        "\n",
        "    x_grid = x_grid.reshape(1, height, width, 1)\n",
        "    y_grid = y_grid.reshape(1, height, width, 1)\n",
        "\n",
        "    u_2, v_2 = _warp_coordinate_generate(depth_maps_1, img_masks, translation_vectors, rotation_matrices,\n",
        "                                         intrinsic_matrices)\n",
        "\n",
        "    return torch.cat(\n",
        "        [(u_2 - x_grid) / torch.tensor(width).float().cuda(), (v_2 - y_grid) / torch.tensor(height).float().cuda()],\n",
        "        dim=-1).permute(0, 3, 1, 2)\n",
        "\n",
        "\n",
        "class DepthWarpingLayer(torch.nn.Module):\n",
        "    def __init__(self, epsilon=1.0e-8):\n",
        "        super(DepthWarpingLayer, self).__init__()\n",
        "        self.zero = torch.tensor(0.0).float().cuda()\n",
        "        self.epsilon = torch.tensor(epsilon).float().cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        depth_maps_1, depth_maps_2, img_masks, translation_vectors, rotation_matrices, intrinsic_matrices = x\n",
        "        warped_depth_maps, intersect_masks = _depth_warping(depth_maps_1, depth_maps_2, img_masks,\n",
        "                                                            translation_vectors,\n",
        "                                                            rotation_matrices, intrinsic_matrices, self.epsilon)\n",
        "        return warped_depth_maps, intersect_masks\n",
        "def _depth_warping(depth_maps_1, depth_maps_2, img_masks, translation_vectors, rotation_matrices,\n",
        "                   intrinsic_matrices, epsilon):\n",
        "    depth_maps_1 = torch.mul(depth_maps_1, img_masks)\n",
        "    depth_maps_2 = torch.mul(depth_maps_2, img_masks)\n",
        "\n",
        "    depth_maps_1 = depth_maps_1.permute(0, 2, 3, 1)\n",
        "    depth_maps_2 = depth_maps_2.permute(0, 2, 3, 1)\n",
        "    img_masks = img_masks.permute(0, 2, 3, 1)\n",
        "\n",
        "    num_batch, height, width, channels = depth_maps_1.shape\n",
        "\n",
        "    y_grid, x_grid = torch.meshgrid(\n",
        "        [torch.arange(start=0, end=height, dtype=torch.float32).cuda(),\n",
        "         torch.arange(start=0, end=width, dtype=torch.float32).cuda()])\n",
        "\n",
        "    x_grid = x_grid.reshape(1, height, width, 1)\n",
        "    y_grid = y_grid.reshape(1, height, width, 1)\n",
        "\n",
        "    ones_grid = torch.ones((1, height, width, 1), dtype=torch.float32).cuda()\n",
        "\n",
        "    eye = torch.eye(3).float().cuda().reshape(1, 3, 3).expand(intrinsic_matrices.shape[0], -1, -1)\n",
        "    intrinsic_matrices_inverse, _ = torch.solve(eye, intrinsic_matrices)\n",
        "    rotation_matrices_inverse = rotation_matrices.transpose(1, 2)\n",
        "\n",
        "    temp_mat = torch.bmm(intrinsic_matrices, rotation_matrices_inverse)\n",
        "    W = torch.bmm(temp_mat, -translation_vectors)\n",
        "    M = torch.bmm(temp_mat, intrinsic_matrices_inverse)\n",
        "\n",
        "    mesh_grid = torch.cat((x_grid, y_grid, ones_grid), dim=-1).reshape(height, width, 3, 1)\n",
        "    intermediate_result = torch.matmul(M.reshape(-1, 1, 1, 3, 3), mesh_grid).reshape(-1, height, width, 3)\n",
        "\n",
        "    depth_maps_2_calculate = W.reshape(-1, 3).narrow(dim=-1, start=2, length=1).reshape(-1, 1, 1, 1) + torch.mul(\n",
        "        depth_maps_1,\n",
        "        intermediate_result.narrow(dim=-1, start=2, length=1).reshape(-1, height,\n",
        "                                                                      width, 1))\n",
        "    depth_maps_2_calculate = torch.where(img_masks > 0.5, depth_maps_2_calculate, epsilon)\n",
        "    depth_maps_2_calculate = torch.where(depth_maps_2_calculate > 0.0, depth_maps_2_calculate, epsilon)\n",
        "\n",
        "    u_2 = (W.reshape(-1, 3).narrow(dim=-1, start=0, length=1).reshape(-1, 1, 1, 1) + torch.mul(depth_maps_1,\n",
        "                                                                                               intermediate_result.narrow(\n",
        "                                                                                                   dim=-1, start=0,\n",
        "                                                                                                   length=1).reshape(-1,\n",
        "                                                                                                                     height,\n",
        "                                                                                                                     width,\n",
        "                                                                                                                     1))) / (\n",
        "              depth_maps_2_calculate)\n",
        "\n",
        "    v_2 = (W.reshape(-1, 3).narrow(dim=-1, start=1, length=1).reshape(-1, 1, 1, 1) + torch.mul(depth_maps_1,\n",
        "                                                                                               intermediate_result.narrow(\n",
        "                                                                                                   dim=-1, start=1,\n",
        "                                                                                                   length=1).reshape(-1,\n",
        "                                                                                                                     height,\n",
        "                                                                                                                     width,\n",
        "                                                                                                                     1))) / (\n",
        "              depth_maps_2_calculate)\n",
        "\n",
        "    W_2 = torch.bmm(intrinsic_matrices, translation_vectors)\n",
        "    M_2 = torch.bmm(torch.bmm(intrinsic_matrices, rotation_matrices), intrinsic_matrices_inverse)\n",
        "\n",
        "    temp = torch.matmul(M_2.reshape(-1, 1, 1, 3, 3), mesh_grid).reshape(-1, height, width, 3).narrow(dim=-1, start=2,\n",
        "                                                                                                     length=1).reshape(\n",
        "        -1,\n",
        "        height,\n",
        "        width, 1)\n",
        "    depth_maps_1_calculate = W_2.reshape(-1, 3).narrow(dim=-1, start=2, length=1).reshape(-1, 1, 1, 1) + torch.mul(\n",
        "        depth_maps_2, temp)\n",
        "    depth_maps_1_calculate = torch.mul(img_masks, depth_maps_1_calculate)\n",
        "\n",
        "    u_2_flat = u_2.reshape(-1)\n",
        "    v_2_flat = v_2.reshape(-1)\n",
        "\n",
        "    warped_depth_maps_2 = _bilinear_interpolate(depth_maps_1_calculate, u_2_flat, v_2_flat).reshape(num_batch, 1,height,width)\n",
        "    intersect_masks = torch.where(_bilinear_interpolate(img_masks, u_2_flat, v_2_flat) * img_masks >= 0.9,\n",
        "                                  torch.tensor(1.0).float().cuda(),\n",
        "                                  torch.tensor(0.0).float().cuda()).reshape(num_batch, 1, height, width)\n",
        "\n",
        "    return [warped_depth_maps_2, intersect_masks]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}